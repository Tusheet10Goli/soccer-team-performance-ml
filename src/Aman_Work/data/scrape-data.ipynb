{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c194c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e4355",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download data - Note that this is commented out because it takes a while to complete, and I already have\n",
    "## all the data downloaded so I don't want to accidnetally trigger this code again. \n",
    "\n",
    "urls = [\n",
    "    \"https://fbref.com/en/comps/9/2017-2018/schedule/2017-2018-Premier-League-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/9/2018-2019/schedule/2018-2019-Premier-League-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/9/2019-2020/schedule/2019-2020-Premier-League-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/9/2020-2021/schedule/2020-2021-Premier-League-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/9/2021-2022/schedule/2021-2022-Premier-League-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/9/2021-2022/schedule/2022-2023-Premier-League-Scores-and-Fixtures\"   \n",
    "]\n",
    "\n",
    "htmls = [requests.get(url).text for url in urls]\n",
    "soups = [BeautifulSoup(html) for html in htmls]\n",
    "tables = [pd.read_html(html)[0] for html in htmls]\n",
    "\n",
    "matchLinks = set()\n",
    "for soup in soups:\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        href = \"https://fbref.com\" + str(link.get(\"href\"))\n",
    "        if href is not None and href.startswith(\"https://fbref.com/en/matches/\") and href.endswith(\"Premier-League\"):\n",
    "            matchLinks.add(href)\n",
    "matchLinks = list(matchLinks)\n",
    "\n",
    "for i in range(len(urls)):\n",
    "    tables[i].to_csv(\"raw-data/{}\".format(urls[i].split(\"/\")[-1]))\n",
    "\n",
    "for matchLink in tqdm(matchLinks):\n",
    "    time.sleep(5) # avoid getting blocked by fbref - overall takes about 3.5 hours to download everything\n",
    "    name = matchLink.split(\"/\")[-1]\n",
    "    tmp = pd.read_html(matchLink)\n",
    "    for index, table in enumerate(tmp):\n",
    "        table.to_csv(\"raw-data/{}-table-{}\".format(name, index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
